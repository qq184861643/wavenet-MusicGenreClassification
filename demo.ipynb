{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from model import *\n",
    "from model_logging import *\n",
    "from model_trainer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "ltype = torch.LongTensor\n",
    "dataset = '../final_dataset_original/'\n",
    "use_cuda=True\n",
    "if use_cuda:\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    ltype = torch.cuda.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ParallelModel()\n",
    "model.dtype = dtype\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "else:\n",
    "    model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = Variable(torch.FloatTensor(16,1,96,1366)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128])\n",
      "torch.Size([16, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 9 \n",
       " 0.4534  0.4754  0.5290  0.5302  0.4786  0.5397  0.5153  0.5090  0.5812  0.4574\n",
       " 0.4817  0.4651  0.5056  0.5974  0.5184  0.5102  0.4810  0.5164  0.5426  0.4149\n",
       " 0.4710  0.4268  0.4772  0.4916  0.4541  0.5571  0.5090  0.5287  0.5630  0.4602\n",
       " 0.4529  0.5008  0.4739  0.5291  0.4974  0.5021  0.5115  0.5259  0.5436  0.4986\n",
       " 0.4579  0.4691  0.5115  0.5495  0.5201  0.5092  0.5155  0.5216  0.5137  0.4555\n",
       " 0.4983  0.5178  0.4838  0.5473  0.4711  0.5139  0.4504  0.4728  0.5161  0.4652\n",
       " 0.4402  0.4622  0.5092  0.4878  0.5068  0.5348  0.4536  0.5327  0.5118  0.4297\n",
       " 0.4616  0.4310  0.4945  0.4940  0.5335  0.5014  0.4996  0.4628  0.5534  0.4655\n",
       " 0.4715  0.5165  0.5058  0.5352  0.4960  0.5499  0.5440  0.5189  0.4860  0.4911\n",
       " 0.4752  0.4534  0.4937  0.4340  0.4479  0.5237  0.4928  0.5311  0.5202  0.4821\n",
       " 0.5006  0.4264  0.4672  0.4955  0.4354  0.4618  0.5015  0.4829  0.5453  0.4985\n",
       " 0.5254  0.4668  0.4549  0.4858  0.4853  0.5351  0.5307  0.5146  0.5383  0.4777\n",
       " 0.4720  0.4237  0.4391  0.4839  0.4628  0.4803  0.4919  0.5466  0.5611  0.4627\n",
       " 0.4458  0.4357  0.5066  0.4612  0.5459  0.5023  0.4988  0.5236  0.5647  0.4597\n",
       " 0.5180  0.3981  0.4456  0.4942  0.5107  0.5178  0.5176  0.4634  0.5622  0.5056\n",
       " 0.5193  0.4450  0.4814  0.5165  0.5110  0.4852  0.5169  0.5690  0.5406  0.4893\n",
       "\n",
       "Columns 10 to 19 \n",
       " 0.5533  0.4873  0.4924  0.4562  0.4613  0.4962  0.5083  0.4716  0.5152  0.5261\n",
       " 0.4939  0.5528  0.4509  0.5561  0.4906  0.6218  0.5024  0.4561  0.4949  0.5427\n",
       " 0.5233  0.5287  0.4422  0.4592  0.4880  0.5091  0.4605  0.4739  0.4761  0.5073\n",
       " 0.5010  0.5062  0.4235  0.4766  0.4667  0.5157  0.4880  0.4698  0.4405  0.5226\n",
       " 0.4979  0.5272  0.4271  0.5228  0.4696  0.5424  0.4972  0.4603  0.5036  0.5219\n",
       " 0.5012  0.4778  0.4488  0.4736  0.4731  0.5466  0.5229  0.4874  0.4692  0.5112\n",
       " 0.5499  0.5177  0.4811  0.4879  0.5286  0.5320  0.4800  0.4498  0.5330  0.4850\n",
       " 0.5174  0.5048  0.4603  0.4675  0.4308  0.5281  0.5280  0.4378  0.4710  0.5071\n",
       " 0.5021  0.5383  0.4949  0.4610  0.4111  0.4671  0.5012  0.4869  0.4768  0.4964\n",
       " 0.5359  0.5028  0.4432  0.4905  0.4552  0.5600  0.5043  0.4279  0.5367  0.5467\n",
       " 0.5005  0.5106  0.4526  0.4545  0.4234  0.6019  0.4822  0.4480  0.4455  0.5180\n",
       " 0.4964  0.5214  0.4757  0.4488  0.4759  0.5004  0.4838  0.4864  0.4745  0.5347\n",
       " 0.5054  0.5380  0.4150  0.4965  0.4786  0.5279  0.4721  0.4270  0.5144  0.5187\n",
       " 0.4603  0.4832  0.4774  0.4836  0.4652  0.4837  0.5767  0.4774  0.4993  0.5215\n",
       " 0.5225  0.5199  0.4240  0.4899  0.4846  0.5443  0.5117  0.4647  0.4889  0.4857\n",
       " 0.4801  0.5291  0.4747  0.4831  0.5215  0.5201  0.5386  0.4441  0.4835  0.4701\n",
       "\n",
       "Columns 20 to 29 \n",
       " 0.5187  0.4745  0.5642  0.4918  0.4961  0.5134  0.5221  0.4826  0.4840  0.5667\n",
       " 0.5719  0.4220  0.5130  0.5216  0.4970  0.5513  0.5005  0.4954  0.4250  0.5410\n",
       " 0.5429  0.4681  0.5536  0.5174  0.5265  0.5347  0.4656  0.4719  0.4685  0.5092\n",
       " 0.4821  0.4767  0.4971  0.4577  0.4860  0.5138  0.4965  0.4836  0.4903  0.5626\n",
       " 0.5427  0.4633  0.5428  0.5498  0.4894  0.5481  0.5019  0.4198  0.4679  0.5562\n",
       " 0.4992  0.4342  0.5476  0.5596  0.4702  0.5468  0.5052  0.4501  0.4601  0.5151\n",
       " 0.5217  0.4568  0.4799  0.5019  0.4862  0.4788  0.4870  0.5420  0.4847  0.5480\n",
       " 0.5444  0.4685  0.5422  0.4937  0.4935  0.5122  0.4930  0.5061  0.4712  0.5301\n",
       " 0.5315  0.4426  0.5114  0.5645  0.4944  0.4823  0.4933  0.5359  0.4733  0.5572\n",
       " 0.5245  0.4366  0.5361  0.4952  0.4892  0.5136  0.4342  0.4685  0.4498  0.5514\n",
       " 0.5363  0.4170  0.5571  0.6053  0.4840  0.5200  0.4770  0.4825  0.4994  0.4980\n",
       " 0.5335  0.4299  0.5181  0.4796  0.5157  0.5110  0.4730  0.4767  0.4668  0.5185\n",
       " 0.5638  0.4185  0.5055  0.5196  0.5046  0.5322  0.4892  0.5200  0.4936  0.5524\n",
       " 0.5358  0.4634  0.5036  0.5216  0.4564  0.5726  0.5452  0.4569  0.4734  0.5496\n",
       " 0.5269  0.4646  0.5159  0.5485  0.4989  0.4416  0.4614  0.5273  0.5104  0.5357\n",
       " 0.5270  0.4810  0.5422  0.5684  0.5030  0.4488  0.5236  0.4940  0.5052  0.4860\n",
       "\n",
       "Columns 30 to 39 \n",
       " 0.4708  0.4622  0.4639  0.4398  0.5062  0.5601  0.4934  0.5171  0.5145  0.5150\n",
       " 0.4638  0.4692  0.5145  0.4754  0.4814  0.4601  0.5330  0.4499  0.5091  0.5320\n",
       " 0.4489  0.4716  0.5236  0.4651  0.4784  0.5182  0.5842  0.4618  0.4748  0.5483\n",
       " 0.4413  0.4368  0.4726  0.4828  0.5158  0.4404  0.5192  0.4904  0.4678  0.4881\n",
       " 0.4927  0.4692  0.5309  0.4648  0.5331  0.5120  0.5227  0.4551  0.4944  0.5085\n",
       " 0.4504  0.4700  0.4688  0.4627  0.5215  0.5102  0.5501  0.5063  0.4867  0.5265\n",
       " 0.5130  0.5004  0.4937  0.4920  0.4506  0.5001  0.5379  0.5098  0.4645  0.5321\n",
       " 0.4595  0.4770  0.4595  0.4671  0.5369  0.4699  0.5492  0.5037  0.4916  0.5250\n",
       " 0.5299  0.4438  0.4749  0.4832  0.5015  0.5048  0.4950  0.5105  0.5347  0.5247\n",
       " 0.4329  0.4709  0.4837  0.4242  0.5058  0.4890  0.5448  0.4440  0.5174  0.5444\n",
       " 0.4313  0.4561  0.4841  0.4796  0.4909  0.5217  0.5960  0.4617  0.4944  0.5120\n",
       " 0.4601  0.4824  0.4378  0.4978  0.5455  0.5162  0.5269  0.4814  0.4864  0.5064\n",
       " 0.4221  0.4884  0.4766  0.4954  0.5562  0.5342  0.5465  0.4348  0.5097  0.5565\n",
       " 0.4366  0.5014  0.4533  0.4626  0.5638  0.4522  0.4673  0.5197  0.4904  0.5029\n",
       " 0.4322  0.4656  0.4382  0.5125  0.5402  0.5155  0.5425  0.4666  0.5665  0.5367\n",
       " 0.4775  0.5042  0.4663  0.5245  0.5385  0.4940  0.5122  0.5177  0.5108  0.5602\n",
       "\n",
       "Columns 40 to 49 \n",
       " 0.4672  0.5190  0.5266  0.4966  0.4734  0.5006  0.5131  0.5315  0.4750  0.4879\n",
       " 0.5089  0.5191  0.4900  0.4838  0.5034  0.4729  0.5431  0.5703  0.4842  0.4830\n",
       " 0.4726  0.4909  0.5045  0.4729  0.4515  0.5267  0.5497  0.5351  0.4909  0.5279\n",
       " 0.4979  0.5020  0.5333  0.4281  0.4578  0.4718  0.5759  0.5375  0.4817  0.4906\n",
       " 0.5076  0.5336  0.4861  0.4581  0.4845  0.4879  0.5441  0.5431  0.5319  0.5139\n",
       " 0.5012  0.5194  0.4599  0.4739  0.4968  0.5106  0.5575  0.5096  0.4907  0.4550\n",
       " 0.4801  0.5127  0.5212  0.4966  0.4778  0.5089  0.6099  0.5402  0.5134  0.4937\n",
       " 0.5312  0.4995  0.5059  0.4840  0.4879  0.5280  0.5382  0.4815  0.5271  0.5244\n",
       " 0.4598  0.5189  0.5357  0.4494  0.4760  0.4893  0.5201  0.5332  0.4812  0.5226\n",
       " 0.4805  0.5027  0.4916  0.5198  0.4621  0.4636  0.4927  0.5610  0.5247  0.4527\n",
       " 0.4772  0.4729  0.4858  0.4656  0.4596  0.4530  0.5013  0.4940  0.5216  0.5396\n",
       " 0.4520  0.5051  0.4767  0.4460  0.4808  0.5358  0.5575  0.5430  0.5254  0.5210\n",
       " 0.4817  0.5437  0.4995  0.4757  0.4435  0.4960  0.5876  0.4907  0.5288  0.4698\n",
       " 0.5114  0.4401  0.5374  0.4552  0.5148  0.4862  0.5967  0.5668  0.5232  0.4973\n",
       " 0.5295  0.4697  0.4877  0.4860  0.4692  0.4779  0.5497  0.5711  0.4740  0.4676\n",
       " 0.4989  0.5581  0.4479  0.4762  0.4764  0.4553  0.5534  0.5231  0.5386  0.4719\n",
       "[torch.cuda.FloatTensor of size 16x50 (GPU 0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train = np.load(dataset+'train_x.npy')\n",
    "Y_train = np.load(dataset+'train_y.npy')\n",
    "\n",
    "Y_train = np.array(Y_train,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "Y_train = torch.LongTensor(Y_train)\n",
    "train_data = torch.utils.data.TensorDataset(data_tensor=X_train,target_tensor=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val = np.load(dataset+'valid_x.npy')\n",
    "Y_val = np.load(dataset+'valid_y.npy')\n",
    "\n",
    "Y_val = np.array(Y_val,dtype=int)\n",
    "\n",
    "X_val = torch.FloatTensor(X_val)\n",
    "Y_val = torch.LongTensor(Y_val)\n",
    "valid_data = torch.utils.data.TensorDataset(data_tensor=X_val,target_tensor=Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer = ModelTrainer(model=model.cuda(),\n",
    "                      lr = 0.0001,\n",
    "                      dataset = train_data,\n",
    "                      validset = valid_data,\n",
    "                      weight_decay = 0.0,\n",
    "                      snapshot_path = 'snapshots',\n",
    "                      snapshot_name = 'saber_model_mix',\n",
    "                      snapshot_interval = 150,\n",
    "                      snapshot_thresh = 9000,\n",
    "                      dtype = dtype,\n",
    "                      ltype = ltype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n",
      "loss at step 14750: 0.155962719023\n",
      "loss at step 14800: 0.108455591649\n",
      "loss at step 14850: 0.108795725554\n",
      "loss at step 14900: 0.105810401738\n",
      "loss at step 14950: 0.112448172122\n",
      "loss at step 15000: 0.111846125573\n",
      "validation loss: 0.12774467242\n",
      "loss at step 15050: 0.108999637663\n",
      "loss at step 15100: 0.111505176723\n",
      "loss at step 15150: 0.112539089769\n",
      "loss at step 15200: 0.109097419232\n",
      "loss at step 15250: 0.109593453258\n",
      "loss at step 15300: 0.108176848441\n",
      "loss at step 15350: 0.105248434991\n",
      "loss at step 15400: 0.108290463984\n",
      "loss at step 15450: 0.110931118727\n",
      "loss at step 15500: 0.115726265162\n",
      "loss at step 15550: 0.110347103328\n",
      "loss at step 15600: 0.111922775656\n",
      "loss at step 15650: 0.109529827386\n",
      "loss at step 15700: 0.110863737017\n",
      "loss at step 15750: 0.110092524737\n",
      "loss at step 15800: 0.109335795939\n",
      "loss at step 15850: 0.109442203939\n",
      "loss at step 15900: 0.111785297245\n",
      "Training took 378 seconds\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "trainer.train(batch_size=16,\n",
    "              epochs=1,\n",
    "              continue_training_at_step = 14700)\n",
    "toc = time.time()\n",
    "print 'Training took %d seconds' %(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = torch.load('snapshots/saber_model_mix_15000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = np.load(dataset+'test_x.npy')\n",
    "y_test = np.load(dataset+'test_y.npy')\n",
    "y_test = np.array(y_test,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = torch.FloatTensor(x_test)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "test_data = torch.utils.data.TensorDataset(data_tensor=x_test,target_tensor=y_test)\n",
    "test_data = torch.utils.data.DataLoader(test_data,\n",
    "                                         batch_size = 8,\n",
    "                                         shuffle = False,\n",
    "                                         num_workers = 8,\n",
    "                                         pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88411909655492382"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = None\n",
    "for x,y in iter(test_data):\n",
    "    x = Variable(x).cuda()\n",
    "    outputs = model(x).view(-1,50)\n",
    "    if y_pred is None:\n",
    "        y_pred = outputs.cpu().data\n",
    "    else:\n",
    "        y_pred = torch.cat((y_pred,outputs.cpu().data),dim=0)\n",
    "\n",
    "y_pred_np = y_pred.numpy()\n",
    "y_test_np = y_test.numpy()\n",
    "\n",
    "\n",
    "test_AUC = roc_auc_score(y_test_np,y_pred_np)\n",
    "\n",
    "test_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.68557332e-02,   2.40016179e-05,   9.86941159e-04,\n",
       "         5.18169761e-01,   2.86673661e-04,   6.48300024e-03,\n",
       "         3.15401703e-04,   5.05167292e-03,   2.33487622e-03,\n",
       "         5.50687253e-01,   1.21358910e-03,   1.08063174e-03,\n",
       "         6.54161302e-03,   5.04257157e-04,   5.39053883e-03,\n",
       "         4.99732676e-04,   1.14320721e-02,   3.56493652e-01,\n",
       "         1.06931627e-02,   4.54413772e-01,   2.57599889e-03,\n",
       "         7.55597603e-06,   8.49293843e-02,   1.13787763e-02,\n",
       "         1.12587493e-03,   3.03875878e-02,   5.02398296e-04,\n",
       "         1.14195189e-03,   8.69585387e-03,   1.45004932e-02,\n",
       "         4.02112395e-01,   6.13199736e-05,   3.89797240e-02,\n",
       "         3.54442117e-03,   9.43347459e-06,   3.50518472e-04,\n",
       "         2.28874665e-02,   1.81105211e-01,   8.87709931e-02,\n",
       "         6.42595291e-02,   2.54248572e-03,   9.47654068e-01,\n",
       "         3.74063035e-03,   5.32258164e-05,   1.57724917e-02,\n",
       "         7.96913719e-06,   5.10627478e-02,   1.90562394e-03,\n",
       "         7.47813829e-05,   6.69637484e-06], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_np[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bc385fce4322>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'snapshots/saber_model_25000'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(model,'snapshots/saber_model_25000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y = iter(valid_data).next()\n",
    "x = Variable(x.contiguous()).cuda().view(1,1366,96)\n",
    "y = Variable(y.type(torch.FloatTensor)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87868866869580142"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.3899\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.binary_cross_entropy(out,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. wavenet: dilation_depth=6, n_blocks=5, output = 64\n",
    "   CNN: feature maps = all 128 , output = 64\n",
    "   Linear: 64+64 -> 512 -> 50\n",
    "   AUC: 88.13\n",
    "2. wavenet: dilation_depth=8, n_blocks=4, output = 64\n",
    "   CNN: feature maps = all 128 , output = 64\n",
    "   Linear: 64+64 -> 512 -> 50\n",
    "   AUC: 88.07\n",
    "3. wavenet: dilation_depth=6, n_blocks=5, output = 128\n",
    "   CNN: feature maps = all 128 , output = 128\n",
    "   Linear: 128+128 -> 512 -> 50\n",
    "   AUC: 88.57\n",
    "\n",
    "4. without dropout with SEnet: 88.45\n",
    "   converge faster，about 0.31seconds per step\n",
    "\n",
    "5. without dropout and SEnet: 88.52\n",
    "   about 0.36 seconds per step\n",
    "   \n",
    "6. replace the activation function with relu at last two linear layer: 88.71 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
