{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from model import *\n",
    "from model_logging import *\n",
    "from model_trainer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "ltype = torch.LongTensor\n",
    "dataset = '../final_dataset_original/'\n",
    "use_cuda=True\n",
    "if use_cuda:\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    ltype = torch.cuda.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ParallelModel()\n",
    "model.dtype = dtype\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "else:\n",
    "    model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelModel(\n",
       "  (cnn): parallel_CNN(\n",
       "    (main): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (2): ELU(alpha=1.0)\n",
       "      (3): MaxPool2d(kernel_size=(2, 4), stride=(2, 4), dilation=(1, 1), ceil_mode=False)\n",
       "      (4): Dropout(p=0.3)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (7): ELU(alpha=1.0)\n",
       "      (8): MaxPool2d(kernel_size=(2, 4), stride=(2, 4), dilation=(1, 1), ceil_mode=False)\n",
       "      (9): Dropout(p=0.3)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (12): ELU(alpha=1.0)\n",
       "      (13): MaxPool2d(kernel_size=(2, 4), stride=(2, 4), dilation=(1, 1), ceil_mode=False)\n",
       "      (14): Dropout(p=0.3)\n",
       "      (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (17): ELU(alpha=1.0)\n",
       "      (18): MaxPool2d(kernel_size=(3, 5), stride=(3, 5), dilation=(1, 1), ceil_mode=False)\n",
       "      (19): Dropout(p=0.4)\n",
       "    )\n",
       "    (conv_end): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (2): ELU(alpha=1.0)\n",
       "      (3): MaxPool2d(kernel_size=(4, 4), stride=(4, 4), dilation=(1, 1), ceil_mode=False)\n",
       "    )\n",
       "    (fc): Linear(in_features=1024, out_features=64, bias=True)\n",
       "  )\n",
       "  (wavenet): CascadeModel(\n",
       "    (first_block): Sequential(\n",
       "      (0): Conv1d(1366, 512, kernel_size=(1,), stride=(1,))\n",
       "      (1): Conv1d(512, 512, kernel_size=(3,), stride=(1,))\n",
       "      (2): Conv1d(512, 512, kernel_size=(3,), stride=(1,))\n",
       "      (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (4): ELU(alpha=1.0)\n",
       "      (5): Dropout(p=0.3)\n",
       "      (6): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Conv1d(512, 512, kernel_size=(3,), stride=(1,))\n",
       "      (8): Conv1d(512, 512, kernel_size=(3,), stride=(1,))\n",
       "      (9): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (10): ELU(alpha=1.0)\n",
       "      (11): Dropout(p=0.3)\n",
       "      (12): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (13): Conv1d(512, 512, kernel_size=(3,), stride=(1,))\n",
       "      (14): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (15): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (16): ELU(alpha=1.0)\n",
       "      (17): Dropout(p=0.3)\n",
       "      (18): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (19): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      (20): ELU(alpha=1.0)\n",
       "      (21): Conv1d(512, 1366, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (wavenet): WaveNet(\n",
       "      (pre_conv): Conv1d(9, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "      (resblocks): ModuleList(\n",
       "        (0): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (1): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (2): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (3): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (4): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (5): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (6): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (7): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (8): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (9): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (10): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (11): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (12): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (13): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (14): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (15): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (16): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (17): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (18): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (19): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (20): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (21): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (22): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (23): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (24): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (25): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (26): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (27): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (28): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "        (29): ResidualBlock(\n",
       "          (filter_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (filter_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (gate_conv): Conv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (gate_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (skip_conv): Conv1d(32, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (skip_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (res_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "          (drop): Dropout(p=0.3)\n",
       "        )\n",
       "      )\n",
       "      (post): Sequential(\n",
       "        (0): ELU(alpha=1.0)\n",
       "        (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (2): ELU(alpha=1.0)\n",
       "        (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (post): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "      (1): ELU(alpha=1.0)\n",
       "      (2): Dropout(p=0.3)\n",
       "      (3): Linear(in_features=256, out_features=50, bias=True)\n",
       "      (4): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (drop): Dropout(p=0.5)\n",
       "  (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train = np.load(dataset+'train_x.npy')\n",
    "Y_train = np.load(dataset+'train_y.npy')\n",
    "\n",
    "Y_train = np.array(Y_train,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "Y_train = torch.LongTensor(Y_train)\n",
    "train_data = torch.utils.data.TensorDataset(data_tensor=X_train,target_tensor=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val = np.load(dataset+'valid_x.npy')\n",
    "Y_val = np.load(dataset+'valid_y.npy')\n",
    "\n",
    "Y_val = np.array(Y_val,dtype=int)\n",
    "\n",
    "X_val = torch.FloatTensor(X_val)\n",
    "Y_val = torch.LongTensor(Y_val)\n",
    "valid_data = torch.utils.data.TensorDataset(data_tensor=X_val,target_tensor=Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     0     1  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "       ...          ⋱          ...       \n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "[torch.LongTensor of size 1521x50]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19773"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer = ModelTrainer(model=model.cuda(),\n",
    "                      lr = 0.0001,\n",
    "                      dataset = train_data,\n",
    "                      validset = valid_data,\n",
    "                      weight_decay = 0.0,\n",
    "                      snapshot_path = 'snapshots',\n",
    "                      snapshot_name = 'saber_model_mix',\n",
    "                      snapshot_interval = 1000,\n",
    "                      snapshot_thresh = 15000,\n",
    "                      dtype = dtype,\n",
    "                      ltype = ltype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n",
      "loss at step 50: 16.1182317543\n",
      "one training step does take approximately0.580104558468 seconds\n",
      "loss at step 100: 10.7678396893\n",
      "loss at step 150: 10.2048993301\n",
      "loss at step 200: 10.0051811981\n",
      "loss at step 250: 10.1084946156\n",
      "loss at step 300: 9.74341536522\n",
      "validation loss: 0.201521808282\n",
      "loss at step 350: 9.74516407013\n",
      "loss at step 400: 10.078715477\n",
      "loss at step 450: 9.75996555328\n",
      "loss at step 500: 9.37055531502\n",
      "loss at step 550: 9.03882510185\n",
      "loss at step 600: 9.78044387817\n",
      "validation loss: 0.206754826009\n",
      "loss at step 650: 9.58391020775\n",
      "loss at step 700: 9.44482924461\n",
      "loss at step 750: 9.31596251488\n",
      "loss at step 800: 8.9603439045\n",
      "loss at step 850: 9.24907625198\n",
      "loss at step 900: 9.03637969017\n",
      "validation loss: 0.18938861244\n",
      "loss at step 950: 9.02555715561\n",
      "loss at step 1000: 9.31499308586\n",
      "loss at step 1050: 8.87181107521\n",
      "loss at step 1100: 8.86765163422\n",
      "loss at step 1150: 8.98432524681\n",
      "loss at step 1200: 9.40077541351\n",
      "validation loss: 0.197512602278\n",
      "epoch  1\n",
      "loss at step 1250: 8.92503661156\n",
      "loss at step 1300: 9.17111963272\n",
      "loss at step 1350: 8.75540641785\n",
      "loss at step 1400: 9.24148933411\n",
      "loss at step 1450: 8.81463884354\n",
      "loss at step 1500: 9.0890053463\n",
      "validation loss: 0.194610915457\n",
      "loss at step 1550: 8.76774271011\n",
      "loss at step 1600: 8.76209429741\n",
      "loss at step 1650: 8.73210959435\n",
      "loss at step 1700: 8.42877532005\n",
      "loss at step 1750: 8.85866892815\n",
      "loss at step 1800: 8.76791315079\n",
      "validation loss: 0.185760553616\n",
      "loss at step 1850: 8.8138667202\n",
      "loss at step 1900: 8.61082588196\n",
      "loss at step 1950: 8.61163899422\n",
      "loss at step 2000: 8.53703755379\n",
      "loss at step 2050: 8.36234966278\n",
      "loss at step 2100: 8.58365592003\n",
      "validation loss: 0.179053032771\n",
      "loss at step 2150: 8.12832268715\n",
      "loss at step 2200: 8.5624832058\n",
      "loss at step 2250: 8.38244804382\n",
      "loss at step 2300: 8.42380373955\n",
      "loss at step 2350: 8.53676016808\n",
      "loss at step 2400: 8.31483380318\n",
      "validation loss: 0.176206989679\n",
      "loss at step 2450: 8.30745310783\n",
      "epoch  2\n",
      "loss at step 2500: 8.43706876755\n",
      "loss at step 2550: 8.25146927834\n",
      "loss at step 2600: 8.25079614639\n",
      "loss at step 2650: 8.33606286049\n",
      "loss at step 2700: 8.13370921135\n",
      "validation loss: 0.184198289799\n",
      "loss at step 2750: 8.47929902077\n",
      "loss at step 2800: 8.34831274986\n",
      "loss at step 2850: 8.17800443649\n",
      "loss at step 2900: 8.03986969948\n",
      "loss at step 2950: 8.25179724693\n",
      "loss at step 3000: 8.06519910812\n",
      "validation loss: 0.167188209637\n",
      "loss at step 3050: 8.01937220573\n",
      "loss at step 3100: 8.13520269394\n",
      "loss at step 3150: 7.68623625755\n",
      "loss at step 3200: 7.6341535759\n",
      "loss at step 3250: 7.97810050011\n",
      "loss at step 3300: 7.7594254303\n",
      "validation loss: 0.165656043372\n",
      "loss at step 3350: 7.79681886673\n",
      "loss at step 3400: 7.90546038628\n",
      "loss at step 3450: 7.91673145294\n",
      "loss at step 3500: 8.04451683998\n",
      "loss at step 3550: 7.84800626755\n",
      "loss at step 3600: 7.97930555344\n",
      "validation loss: 0.16120573304\n",
      "loss at step 3650: 7.84517039299\n",
      "loss at step 3700: 7.70096123695\n",
      "epoch  3\n",
      "loss at step 3750: 7.98232853889\n",
      "loss at step 3800: 7.88358663559\n",
      "loss at step 3850: 7.63036037445\n",
      "loss at step 3900: 7.41997635841\n",
      "validation loss: 0.155784390091\n",
      "loss at step 3950: 7.7449454689\n",
      "loss at step 4000: 7.25993551254\n",
      "loss at step 4050: 7.46344424248\n",
      "loss at step 4100: 7.919898386\n",
      "loss at step 4150: 7.75810056686\n",
      "loss at step 4200: 7.9953288269\n",
      "validation loss: 0.1613237001\n",
      "loss at step 4250: 7.88962872505\n",
      "loss at step 4300: 7.76349947929\n",
      "loss at step 4350: 7.61930158615\n",
      "loss at step 4400: 7.57706440926\n",
      "loss at step 4450: 7.59358160973\n",
      "loss at step 4500: 7.75862735748\n",
      "validation loss: 0.152832350771\n",
      "loss at step 4550: 7.45705234528\n",
      "loss at step 4600: 7.61581906319\n",
      "loss at step 4650: 7.82699530602\n",
      "loss at step 4700: 7.59865559578\n",
      "loss at step 4750: 8.05396026611\n",
      "loss at step 4800: 7.460816679\n",
      "validation loss: 0.156948414398\n",
      "loss at step 4850: 7.66934246063\n",
      "loss at step 4900: 7.39034095764\n",
      "epoch  4\n",
      "loss at step 4950: 7.64473987579\n",
      "loss at step 5000: 7.65561520576\n",
      "loss at step 5050: 7.56427921295\n",
      "loss at step 5100: 7.39128386497\n",
      "validation loss: 0.158824403072\n",
      "loss at step 5150: 7.25416417122\n",
      "loss at step 5200: 8.18645630836\n",
      "loss at step 5250: 7.49346129417\n",
      "loss at step 5300: 7.68030105591\n",
      "loss at step 5350: 7.46219809532\n",
      "loss at step 5400: 7.23339519501\n",
      "validation loss: 0.152539822195\n",
      "loss at step 5450: 7.28514657021\n",
      "loss at step 5500: 7.36238292694\n",
      "loss at step 5550: 7.22579805374\n",
      "loss at step 5600: 7.27789578438\n",
      "loss at step 5650: 7.52190594673\n",
      "loss at step 5700: 7.57203148842\n",
      "validation loss: 0.151162124161\n",
      "loss at step 5750: 7.21787676811\n",
      "loss at step 5800: 7.67538523674\n",
      "loss at step 5850: 7.3385857296\n",
      "loss at step 5900: 7.57774263382\n",
      "loss at step 5950: 7.58139428139\n",
      "loss at step 6000: 7.53997363091\n",
      "validation loss: 0.153853452299\n",
      "loss at step 6050: 7.47400918961\n",
      "loss at step 6100: 7.47871695042\n",
      "loss at step 6150: 7.20074982643\n",
      "epoch  5\n",
      "loss at step 6200: 7.48094952583\n",
      "loss at step 6250: 7.41251753807\n",
      "loss at step 6300: 7.59884090424\n",
      "validation loss: 0.153222793636\n",
      "loss at step 6350: 7.68971541405\n",
      "loss at step 6400: 7.3309383297\n",
      "loss at step 6450: 7.16753305435\n",
      "loss at step 6500: 7.4549806118\n",
      "loss at step 6550: 7.49132006645\n",
      "loss at step 6600: 7.4584799099\n",
      "validation loss: 0.148922800474\n",
      "loss at step 6650: 7.45575014114\n",
      "loss at step 6700: 7.48791157722\n",
      "loss at step 6750: 7.16386617661\n",
      "loss at step 6800: 7.0508763504\n",
      "loss at step 6850: 7.15356121063\n",
      "loss at step 6900: 7.62368555069\n",
      "validation loss: 0.148566638818\n",
      "loss at step 6950: 7.05235098839\n",
      "loss at step 7000: 7.62782998085\n",
      "loss at step 7050: 7.06971383095\n",
      "loss at step 7100: 7.62225356102\n",
      "loss at step 7150: 7.30953329086\n",
      "loss at step 7200: 7.36334299088\n",
      "validation loss: 0.148979789577\n",
      "loss at step 7250: 7.17364803314\n",
      "loss at step 7300: 7.33225288391\n",
      "loss at step 7350: 7.26077332497\n",
      "loss at step 7400: 7.56192608833\n",
      "epoch  6\n",
      "loss at step 7450: 7.51858892441\n",
      "loss at step 7500: 7.30480926514\n",
      "validation loss: 0.150037906986\n",
      "loss at step 7550: 7.30713043213\n",
      "loss at step 7600: 7.22131542206\n",
      "loss at step 7650: 7.10114060402\n",
      "loss at step 7700: 7.46536037445\n",
      "loss at step 7750: 7.54874400139\n",
      "loss at step 7800: 7.08780983925\n",
      "validation loss: 0.14411936452\n",
      "loss at step 7850: 7.10423474312\n",
      "loss at step 7900: 7.39698880196\n",
      "loss at step 7950: 7.22791308403\n",
      "loss at step 8000: 7.6185696125\n",
      "loss at step 8050: 7.32451234818\n",
      "loss at step 8100: 7.17817461967\n",
      "validation loss: 0.146977323185\n",
      "loss at step 8150: 7.46515802383\n",
      "loss at step 8200: 7.31303778648\n",
      "loss at step 8250: 7.30604716301\n",
      "loss at step 8300: 6.92107234955\n",
      "loss at step 8350: 7.05857147217\n",
      "loss at step 8400: 7.40638303757\n",
      "validation loss: 0.148808174534\n",
      "loss at step 8450: 7.22555818558\n",
      "loss at step 8500: 7.30632123947\n",
      "loss at step 8550: 7.30140792847\n",
      "loss at step 8600: 7.34656015396\n",
      "epoch  7\n",
      "loss at step 8650: 7.01800177574\n",
      "loss at step 8700: 7.16616615295\n",
      "validation loss: 0.142407380665\n",
      "loss at step 8750: 6.97022798538\n",
      "loss at step 8800: 7.16536541939\n",
      "loss at step 8850: 7.00926206589\n",
      "loss at step 8900: 7.3376901722\n",
      "loss at step 8950: 6.93337521553\n",
      "loss at step 9000: 7.05375965118\n",
      "validation loss: 0.140253867333\n",
      "loss at step 9050: 7.09589008331\n",
      "loss at step 9100: 7.43034252167\n",
      "loss at step 9150: 7.20851905823\n",
      "loss at step 9200: 7.07935647011\n",
      "loss at step 9250: 7.41299575806\n",
      "loss at step 9300: 7.29530377388\n",
      "validation loss: 0.143536867729\n",
      "loss at step 9350: 7.13681208611\n",
      "loss at step 9400: 7.34426509857\n",
      "loss at step 9450: 7.30960957527\n",
      "loss at step 9500: 7.09703222275\n",
      "loss at step 9550: 6.88414535522\n",
      "loss at step 9600: 7.22231638908\n",
      "validation loss: 0.146672134909\n",
      "loss at step 9650: 7.23918669701\n",
      "loss at step 9700: 7.36817708015\n",
      "loss at step 9750: 7.49058652878\n",
      "loss at step 9800: 6.94990848541\n",
      "loss at step 9850: 7.08318863869\n",
      "epoch  8\n",
      "loss at step 9900: 6.92387097359\n",
      "validation loss: 0.139345977378\n",
      "loss at step 9950: 7.10953549385\n",
      "loss at step 10000: 6.96151310921\n",
      "loss at step 10050: 7.19412500381\n",
      "loss at step 10100: 6.94737221718\n",
      "loss at step 10150: 7.38900724411\n",
      "loss at step 10200: 7.25972665787\n",
      "validation loss: 0.143034868874\n",
      "loss at step 10250: 7.02818728447\n",
      "loss at step 10300: 7.20803081512\n",
      "loss at step 10350: 7.13134908676\n",
      "loss at step 10400: 7.52905730247\n",
      "loss at step 10450: 7.08270301819\n",
      "loss at step 10500: 7.27133795738\n",
      "validation loss: 0.144350260496\n",
      "loss at step 10550: 7.03186327934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at step 10600: 7.03653639793\n",
      "loss at step 10650: 6.98360082626\n",
      "loss at step 10700: 6.98208428383\n",
      "loss at step 10750: 7.06061577797\n",
      "loss at step 10800: 7.05982876778\n",
      "validation loss: 0.143830185446\n",
      "loss at step 10850: 7.00743257523\n",
      "loss at step 10900: 7.18249960899\n",
      "loss at step 10950: 6.73540006638\n",
      "loss at step 11000: 7.00773741722\n",
      "loss at step 11050: 7.08065610886\n",
      "loss at step 11100: 6.89365590096\n",
      "validation loss: 0.140953784032\n",
      "epoch  9\n",
      "loss at step 11150: 6.91450058937\n",
      "loss at step 11200: 6.64370184898\n",
      "loss at step 11250: 7.09882296562\n",
      "loss at step 11300: 7.23919948578\n",
      "loss at step 11350: 7.18205123901\n",
      "loss at step 11400: 7.06429057121\n",
      "validation loss: 0.146412189972\n",
      "loss at step 11450: 7.2727712059\n",
      "loss at step 11500: 7.05557605743\n",
      "loss at step 11550: 7.1721199131\n",
      "loss at step 11600: 6.95869882584\n",
      "loss at step 11650: 7.09379043579\n",
      "loss at step 11700: 7.02035568237\n",
      "validation loss: 0.137430660892\n",
      "loss at step 11750: 7.09597436905\n",
      "loss at step 11800: 6.92516767502\n",
      "loss at step 11850: 6.70671214104\n",
      "loss at step 11900: 6.95983242035\n",
      "loss at step 11950: 6.98686451912\n",
      "loss at step 12000: 7.24340504646\n",
      "validation loss: 0.137325949579\n",
      "loss at step 12050: 6.78251707077\n",
      "loss at step 12100: 6.8412104702\n",
      "loss at step 12150: 7.00563534737\n",
      "loss at step 12200: 7.02867132187\n",
      "loss at step 12250: 6.99438456535\n",
      "loss at step 12300: 6.77399749756\n",
      "validation loss: 0.141988813722\n",
      "loss at step 12350: 6.984662714\n",
      "epoch  10\n",
      "loss at step 12400: 7.10849954605\n",
      "loss at step 12450: 6.59581199646\n",
      "loss at step 12500: 6.93282985687\n",
      "loss at step 12550: 6.791147995\n",
      "loss at step 12600: 6.66327854156\n",
      "validation loss: 0.141922437741\n",
      "loss at step 12650: 6.80354392052\n",
      "loss at step 12700: 7.07196015358\n",
      "loss at step 12750: 6.98906846046\n",
      "loss at step 12800: 6.92873644829\n",
      "loss at step 12850: 6.84794664383\n",
      "loss at step 12900: 6.90471538067\n",
      "validation loss: 0.135303901353\n",
      "loss at step 12950: 7.18384306908\n",
      "loss at step 13000: 6.78473362923\n",
      "loss at step 13050: 6.83628423691\n",
      "loss at step 13100: 6.96068874359\n",
      "loss at step 13150: 7.15469242096\n",
      "loss at step 13200: 6.97804753304\n",
      "validation loss: 0.144279248004\n",
      "loss at step 13250: 6.70817440987\n",
      "loss at step 13300: 6.64298505783\n",
      "loss at step 13350: 6.82575014114\n",
      "loss at step 13400: 7.10593669891\n",
      "loss at step 13450: 6.81778146744\n",
      "loss at step 13500: 7.11501958847\n",
      "validation loss: 0.140625252466\n",
      "loss at step 13550: 7.22779442787\n",
      "epoch  11\n",
      "loss at step 13600: 7.18390144348\n",
      "loss at step 13650: 6.79062299728\n",
      "loss at step 13700: 6.91967445374\n",
      "loss at step 13750: 6.73308586121\n",
      "loss at step 13800: 6.80142532349\n",
      "validation loss: 0.139239709824\n",
      "loss at step 13850: 6.75511706352\n",
      "loss at step 13900: 6.79493742943\n",
      "loss at step 13950: 6.90737488747\n",
      "loss at step 14000: 6.63577129364\n",
      "loss at step 14050: 6.89389667511\n",
      "loss at step 14100: 7.23580465317\n",
      "validation loss: 0.140593767011\n",
      "loss at step 14150: 6.69821433067\n",
      "loss at step 14200: 7.10719605446\n",
      "loss at step 14250: 6.90303201675\n",
      "loss at step 14300: 6.6888079071\n",
      "loss at step 14350: 7.04252662659\n",
      "loss at step 14400: 7.07304850578\n",
      "validation loss: 0.136112013444\n",
      "loss at step 14450: 6.91536946297\n",
      "loss at step 14500: 6.84444981575\n",
      "loss at step 14550: 7.04213519096\n",
      "loss at step 14600: 6.8179054451\n",
      "loss at step 14650: 6.77666752815\n",
      "loss at step 14700: 6.63394863129\n",
      "validation loss: 0.137630992259\n",
      "loss at step 14750: 6.91147172928\n",
      "loss at step 14800: 6.97691511154\n",
      "epoch  12\n",
      "loss at step 14850: 6.70675451279\n",
      "loss at step 14900: 6.97265930176\n",
      "loss at step 14950: 6.7892418766\n",
      "loss at step 15000: 6.75983444214\n",
      "validation loss: 0.137244549114\n",
      "loss at step 15050: 6.88336680412\n",
      "loss at step 15100: 6.8968522644\n",
      "loss at step 15150: 6.58250185966\n",
      "loss at step 15200: 6.73158828735\n",
      "loss at step 15250: 6.88676237106\n",
      "loss at step 15300: 6.73115361214\n",
      "validation loss: 0.134276855116\n",
      "loss at step 15350: 6.82272933006\n",
      "loss at step 15400: 6.84298624039\n",
      "loss at step 15450: 6.73324890137\n",
      "loss at step 15500: 6.72530822754\n",
      "loss at step 15550: 6.91391163826\n",
      "loss at step 15600: 6.96419906616\n",
      "validation loss: 0.137234826339\n",
      "loss at step 15650: 7.13576637268\n",
      "loss at step 15700: 6.79395531654\n",
      "loss at step 15750: 6.72868108749\n",
      "loss at step 15800: 6.62394161224\n",
      "loss at step 15850: 6.84181042671\n",
      "loss at step 15900: 6.9171425724\n",
      "validation loss: 0.137455150485\n",
      "loss at step 15950: 6.73211530685\n",
      "loss at step 16000: 6.61006141663\n",
      "loss at step 16050: 6.89312397957\n",
      "epoch  13\n",
      "loss at step 16100: 6.252551651\n",
      "loss at step 16150: 6.89538806915\n",
      "loss at step 16200: 6.61076647758\n",
      "validation loss: 0.13652973948\n",
      "loss at step 16250: 6.66654211998\n",
      "loss at step 16300: 6.73646807671\n",
      "loss at step 16350: 6.98954559326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-532:\n",
      "Process Process-533:\n",
      "Process Process-536:\n",
      "Process Process-535:\n",
      "Process Process-531:\n",
      "Process Process-529:\n",
      "Traceback (most recent call last):\n",
      "Process Process-530:\n",
      "Process Process-534:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/software/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "  File \"/home/software/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/software/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/software/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "  File \"/home/software/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "    r = index_queue.get()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    r = index_queue.get()\n",
      "    r = index_queue.get()\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "    r = index_queue.get()\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "  File \"/home/software/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "  File \"/home/software/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    racquire()\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "  File \"/home/software/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    racquire()\n",
      "    r = index_queue.get()\n",
      "    racquire()\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    r = index_queue.get()\n",
      "    r = index_queue.get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "    return recv()\n",
      "KeyboardInterrupt\n",
      "    racquire()\n",
      "  File \"/home/software/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/software/anaconda2/lib/python2.7/site-packages/torch/multiprocessing/queue.py\", line 21, in recv\n",
      "    buf = self.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Exception socket.error: error(2, 'No such file or directory') in <bound method DataLoaderIter.__del__ of <torch.utils.data.dataloader.DataLoaderIter object at 0x7fbd582d5190>> ignored\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4a71b6f2b51e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m trainer.train(batch_size=16,\n\u001b[1;32m      3\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m               continue_training_at_step = 0)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Training took %d seconds'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoc\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/fengchuyi/ProjectforDL/label-wavenet/model_trainer.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, batch_size, epochs, continue_training_at_step)\u001b[0m\n\u001b[1;32m     78\u001b[0m                                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/software/anaconda2/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/software/anaconda2/lib/python2.7/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "trainer.train(batch_size=16,\n",
    "              epochs=23,\n",
    "              continue_training_at_step = 0)\n",
    "toc = time.time()\n",
    "print 'Training took %d seconds' %(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = torch.load('snapshots/saber_model_mix_24000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = np.load(dataset+'test_x.npy')\n",
    "y_test = np.load(dataset+'test_y.npy')\n",
    "y_test = np.array(y_test,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = torch.FloatTensor(x_test)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "test_data = torch.utils.data.TensorDataset(data_tensor=x_test,target_tensor=y_test)\n",
    "test_data = torch.utils.data.DataLoader(test_data,\n",
    "                                         batch_size = 16,\n",
    "                                         shuffle = False,\n",
    "                                         num_workers = 8,\n",
    "                                         pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = None\n",
    "for x,y in iter(test_data):\n",
    "    x = Variable(x).cuda()\n",
    "    outputs = model(x).view(-1,50)\n",
    "    if y_pred is None:\n",
    "        y_pred = outputs.cpu().data\n",
    "    else:\n",
    "        y_pred = torch.cat((y_pred,outputs.cpu().data),dim=0)\n",
    "\n",
    "y_pred_np = y_pred.numpy()\n",
    "y_test_np = y_test.numpy()\n",
    "\n",
    "\n",
    "test_AUC = roc_auc_score(y_test_np,y_pred_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87947828202008549"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model,'snapshots/saber_model_25000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y = iter(valid_data).next()\n",
    "x = Variable(x.contiguous()).cuda().view(1,1366,96)\n",
    "y = Variable(y.type(torch.FloatTensor)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.3899\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.binary_cross_entropy(out,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. wavenet: dilation_depth=6, n_blocks=5, output = 64\n",
    "   CNN: feature maps = all 128 , output = 64\n",
    "   Linear: 64+64 -> 512 -> 50\n",
    "   AUC: 88.13\n",
    "2. wavenet: dilation_depth=8, n_blocks=4, output = 64\n",
    "   CNN: feature maps = all 128 , output = 64\n",
    "   Linear: 64+64 -> 512 -> 50\n",
    "   AUC: 88.07\n",
    "3. wavenet: dilation_depth=6, n_blocks=5, output = 128\n",
    "   CNN: feature maps = all 128 , output = 128\n",
    "   Linear: 128+128 -> 512 -> 50\n",
    "   AUC: 88.57"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
